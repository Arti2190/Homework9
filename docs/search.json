[
  {
    "objectID": "HW09.html",
    "href": "HW09.html",
    "title": "HW09withjustin",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "HW09.html#quarto",
    "href": "HW09.html#quarto",
    "title": "HW09withjustin",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "HW09.html#running-code",
    "href": "HW09.html#running-code",
    "title": "HW09withjustin",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).\n\n#install.packages(\"tree\")\n#install.packages(\"rpart.plot\")\n#install.packages(\"baguette\")\n#install.packages(\"ranger\")\n#install.packages(\"vip\")\n#install.packages(\"parsnip\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(readr)\nlibrary(lubridate)\nlibrary(baguette)\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(rpart)\nlibrary(tree)\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.4.1\n\nlibrary(\"vip\")\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(\"parsnip\")\n\n\nbike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\",local = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbike_data\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\n\n bike_data |&gt; \n  is.na() |&gt; \n  colSums()\n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\n\nattributes(bike_data)$spec\n\ncols(\n  Date = col_character(),\n  `Rented Bike Count` = col_double(),\n  Hour = col_double(),\n  `Temperature(°C)` = col_double(),\n  `Humidity(%)` = col_double(),\n  `Wind speed (m/s)` = col_double(),\n  `Visibility (10m)` = col_double(),\n  `Dew point temperature(°C)` = col_double(),\n  `Solar Radiation (MJ/m2)` = col_double(),\n  `Rainfall(mm)` = col_double(),\n  `Snowfall (cm)` = col_double(),\n  Seasons = col_character(),\n  Holiday = col_character(),\n  `Functioning Day` = col_character()\n)\n\n\n\n# Change date column \nbike_data &lt;- bike_data |&gt;\n  mutate(date = dmy(Date)) |&gt;\n  select(-Date)\n\n\nsummary(bike_data)\n\n Rented Bike Count      Hour       Temperature(°C)   Humidity(%)   \n Min.   :   0.0    Min.   : 0.00   Min.   :-17.80   Min.   : 0.00  \n 1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50   1st Qu.:42.00  \n Median : 504.5    Median :11.50   Median : 13.70   Median :57.00  \n Mean   : 704.6    Mean   :11.50   Mean   : 12.88   Mean   :58.23  \n 3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50   3rd Qu.:74.00  \n Max.   :3556.0    Max.   :23.00   Max.   : 39.40   Max.   :98.00  \n Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :1.500    Median :1698     Median :  5.100          \n Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)       Seasons         \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000   Length:8760       \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000   Class :character  \n Median :0.0100          Median : 0.0000   Median :0.00000   Mode  :character  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507                     \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000                     \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000                     \n   Holiday          Functioning Day         date           \n Length:8760        Length:8760        Min.   :2017-12-01  \n Class :character   Class :character   1st Qu.:2018-03-02  \n Mode  :character   Mode  :character   Median :2018-06-01  \n                                       Mean   :2018-06-01  \n                                       3rd Qu.:2018-08-31  \n                                       Max.   :2018-11-30  \n\n\n\nprint(bike_data$Seasons |&gt; \n        unique())\n\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n\n\nbike_data$Holiday |&gt;\n  unique()\n\n[1] \"No Holiday\" \"Holiday\"   \n\n\n\nbike_data$`Functioning Day` |&gt;\n  unique()\n\n[1] \"Yes\" \"No\" \n\n\n\nTurn it into factor to categorical data\n\nbike_data &lt;- bike_data |&gt;\n  mutate(seasons = factor(Seasons),\n         holiday = factor(Holiday),\n         fn_day = factor(`Functioning Day`)) |&gt;\n  select(-Seasons, -Holiday, - `Functioning Day`)\n\n\nbike_data &lt;- bike_data |&gt; rename('bike_count' = `Rented Bike Count`,\n         'hour' = \"Hour\",\n         \"temp\" = `Temperature(°C)`,\n         \"wind_speed\" = `Wind speed (m/s)`,\n         \"humidity\" = `Humidity(%)`,\n         \"vis\" = `Visibility (10m)`,\n         \"dew_point_temp\" = `Dew point temperature(°C)`,\n         \"solar_radiation\" = `Solar Radiation (MJ/m2)`,\n         \"rainfall\" = \"Rainfall(mm)\",\n         \"snowfall\" = `Snowfall (cm)`)\n\n\nbike_data &lt;- bike_data |&gt;\n  filter(fn_day == \"Yes\") |&gt;\n  select(-fn_day)\n\n\nbike_data &lt;- bike_data |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarize(bike_count = sum(bike_count),\n            temp = mean(temp),\n            humidity = mean(humidity),\n            wind_speed = mean(wind_speed),\n            vis = mean(vis),\n            dew_point_temp = mean(dew_point_temp),\n            solar_radiation = mean(solar_radiation),\n            rainfall = sum(rainfall),\n            snowfall = sum(snowfall))|&gt;\n  ungroup()\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\n\n\nbike_data\n\n# A tibble: 353 × 12\n   date       seasons holiday    bike_count    temp humidity wind_speed   vis\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday       9539 -2.45       45.9      1.54  1871.\n 2 2017-12-02 Winter  No Holiday       8523  1.33       62.0      1.71  1471.\n 3 2017-12-03 Winter  No Holiday       7222  4.88       81.5      1.61   456.\n 4 2017-12-04 Winter  No Holiday       8729 -0.304      52.5      3.45  1363.\n 5 2017-12-05 Winter  No Holiday       8307 -4.46       36.4      1.11  1959.\n 6 2017-12-06 Winter  No Holiday       6669  0.0458     70.8      0.696 1187.\n 7 2017-12-07 Winter  No Holiday       8549  1.09       67.5      1.69   949.\n 8 2017-12-08 Winter  No Holiday       8032 -3.82       41.8      1.85  1872.\n 9 2017-12-09 Winter  No Holiday       7233 -0.846      46        1.08  1861.\n10 2017-12-10 Winter  No Holiday       3453  1.19       69.7      2.00  1043.\n# ℹ 343 more rows\n# ℹ 4 more variables: dew_point_temp &lt;dbl&gt;, solar_radiation &lt;dbl&gt;,\n#   rainfall &lt;dbl&gt;, snowfall &lt;dbl&gt;\n\n\n\n\n\nSummary Stats & Graphs\n\nbike_data |&gt;\n  summarize(across('bike_count',\n                   .fns = c(\"mean \"= mean,\n                            \"median\" = median,\n                            \"sd\" = sd,\n                            \"IQR\" = IQR,\n                            \"min\" = min,\n                            \"max\" = max),\n                   .names = \"{.col}_{.fn}\"))\n\n# A tibble: 1 × 6\n  `bike_count_mean ` bike_count_median bike_count_sd bike_count_IQR\n               &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n1             17485.             18563         9937.          19318\n# ℹ 2 more variables: bike_count_min &lt;dbl&gt;, bike_count_max &lt;dbl&gt;\n\n\n\nbike_data |&gt;\n  group_by(holiday)|&gt;\n  summarize(across('bike_count',\n                   .fns = c(\"mean \"= mean,\n                            \"median\" = median,\n                            \"sd\" = sd,\n                            \"IQR\" = IQR,\n                            \"min\" = min,\n                            \"max\" = max),\n                   .names = \"{.col}_{.fn}\"))\n\n# A tibble: 2 × 7\n  holiday    `bike_count_mean ` bike_count_median bike_count_sd bike_count_IQR\n  &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n1 Holiday                12700.             7184         10504.         16576 \n2 No Holiday             17727.            19104.         9862.         19168.\n# ℹ 2 more variables: bike_count_min &lt;dbl&gt;, bike_count_max &lt;dbl&gt;\n\n\n\nbike_data |&gt;\n  group_by(seasons)|&gt;\n  summarize(across('bike_count',\n                   .fns = c(\"mean \"= mean,\n                            \"median\" = median,\n                            \"sd\" = sd,\n                            \"IQR\" = IQR,\n                            \"min\" = min,\n                            \"max\" = max),\n                   .names = \"{.col}_{.fn}\"))\n\n# A tibble: 4 × 7\n  seasons `bike_count_mean ` bike_count_median bike_count_sd bike_count_IQR\n  &lt;fct&gt;                &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n1 Autumn              22099.            23350          6711.         10733 \n2 Spring              17910.            17590          8357.         14362.\n3 Summer              24818.            25572.         7297.          9308.\n4 Winter               5413.             5498          1808.          2634.\n# ℹ 2 more variables: bike_count_min &lt;dbl&gt;, bike_count_max &lt;dbl&gt;\n\n\n\nbike_data |&gt;\n  group_by(seasons,holiday) |&gt;\n  summarize(across('bike_count',\n                   .fns = c(\"mean \"= mean,\n                            \"median\" = median,\n                            \"sd\" = sd,\n                            \"IQR\" = IQR,\n                            \"min\" = min,\n                            \"max\" = max),\n                   .names = \"{.col}_{.fn}\"))\n\n`summarise()` has grouped output by 'seasons'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 8\n# Groups:   seasons [4]\n  seasons holiday    `bike_count_mean ` bike_count_median bike_count_sd\n  &lt;fct&gt;   &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 Autumn  Holiday                22754.            21705          5642.\n2 Autumn  No Holiday             22065.            23472          6792.\n3 Spring  Holiday                15247.            13790         10917.\n4 Spring  No Holiday             18002.            17730          8322.\n5 Summer  Holiday                24532.            24532.         8438.\n6 Summer  No Holiday             24824.            25572.         7324.\n7 Winter  Holiday                 3759              3454.         1561.\n8 Winter  No Holiday              5574.             5609          1757.\n# ℹ 3 more variables: bike_count_IQR &lt;dbl&gt;, bike_count_min &lt;dbl&gt;,\n#   bike_count_max &lt;dbl&gt;\n\n\n\nbike_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n                bike_count   temp humidity wind_speed    vis dew_point_temp\nbike_count           1.000  0.753    0.036     -0.193  0.166          0.650\ntemp                 0.753  1.000    0.404     -0.261  0.002          0.963\nhumidity             0.036  0.404    1.000     -0.234 -0.559          0.632\nwind_speed          -0.193 -0.261   -0.234      1.000  0.206         -0.288\nvis                  0.166  0.002   -0.559      0.206  1.000         -0.154\ndew_point_temp       0.650  0.963    0.632     -0.288 -0.154          1.000\nsolar_radiation      0.736  0.550   -0.274      0.096  0.271          0.383\nrainfall            -0.239  0.145    0.529     -0.102 -0.222          0.265\nsnowfall            -0.265 -0.267    0.065      0.021 -0.102         -0.210\n                solar_radiation rainfall snowfall\nbike_count                0.736   -0.239   -0.265\ntemp                      0.550    0.145   -0.267\nhumidity                 -0.274    0.529    0.065\nwind_speed                0.096   -0.102    0.021\nvis                       0.271   -0.222   -0.102\ndew_point_temp            0.383    0.265   -0.210\nsolar_radiation           1.000   -0.323   -0.233\nrainfall                 -0.323    1.000   -0.023\nsnowfall                 -0.233   -0.023    1.000\n\n\n\nggplot(bike_data, aes(x = temp, y = bike_count)) +\n  geom_jitter(aes(color = seasons)) +\n  facet_grid(~holiday)\n\n\n\n\n\n\n\n\n\nggplot(bike_data, aes(x = solar_radiation, y = bike_count)) +\n  geom_jitter(aes(color = seasons)) +\n  facet_grid(~holiday)\n\n\n\n\n\n\n\n\n\nset.seed(23)\nbike_split &lt;- initial_split(bike_data, prop = 0.75, strata = seasons)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\nbike_10_fold &lt;- vfold_cv(bike_train, 10)\n\n\nMLR_rec1 &lt;- recipe(bike_count ~., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_dummy(seasons, holiday, day_type) |&gt;\n  step_normalize(all_numeric(), -bike_count)\n\n\nMLR_rec2 &lt;- MLR_rec1 |&gt;\n  step_interact(terms = ~starts_with(\"seasons\")*starts_with(\"holiday\") +\n                  starts_with(\"seasons\")*temp +\n                  temp*rainfall)\n\n\nMLR_rec3 &lt;- MLR_rec2 |&gt;\n  step_poly(temp,\n            wind_speed,\n            vis,\n            dew_point_temp,\n            solar_radiation,\n            rainfall,\n            snowfall,\n            degree = 2)\n\n#MLR_rec3\n\n\nMLR_spec &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\n\nMLR_CV_fit1 &lt;- workflow() |&gt;\n  add_recipe(MLR_rec1) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(bike_10_fold)\n\n\nMLR_CV_fit2 &lt;- workflow() |&gt;\n  add_recipe(MLR_rec2) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(bike_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n\n\nMLR_CV_fit3 &lt;- workflow() |&gt;\n  add_recipe(MLR_rec3) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(bike_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\n\nrbind(MLR_CV_fit1 |&gt; collect_metrics(),\n      MLR_CV_fit2 |&gt; collect_metrics(),\n      MLR_CV_fit3 |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4173.       10 147.      Preprocessor1_Model1\n2 rsq     standard      0.838    10   0.0156  Preprocessor1_Model1\n3 rmse    standard   2831.       10 138.      Preprocessor1_Model1\n4 rsq     standard      0.921    10   0.00725 Preprocessor1_Model1\n5 rmse    standard   2750.       10 143.      Preprocessor1_Model1\n6 rsq     standard      0.923    10   0.00863 Preprocessor1_Model1\n\n\n\nrbind(MLR_CV_fit1 |&gt; collect_metrics() |&gt; filter(.metric == \"rmse\"),\n      MLR_CV_fit2 |&gt; collect_metrics() |&gt; filter(.metric == \"rmse\"),\n      MLR_CV_fit3 |&gt; collect_metrics() |&gt; filter(.metric == \"rmse\")) |&gt;\n  mutate(Model = c(\"Model1 \", \"Model 2\", \"Model 3\")) |&gt;\n  select(Model, mean, n, std_err)\n\n# A tibble: 3 × 4\n  Model      mean     n std_err\n  &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 \"Model1 \" 4173.    10    147.\n2 \"Model 2\" 2831.    10    138.\n3 \"Model 3\" 2750.    10    143.\n\n\n\nfinal_fit &lt;- workflow() |&gt;\n  add_recipe(MLR_rec1) |&gt;\n  add_model(MLR_spec) |&gt;\n  last_fit(bike_split)\n\n\nfinal_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3847.    Preprocessor1_Model1\n2 rsq     standard       0.840 Preprocessor1_Model1\n\n\n\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 5\n   term               estimate std.error statistic   p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          17670.      256.    69.1   1.60e-164\n 2 temp                 -3580.     4750.    -0.754 4.52e-  1\n 3 humidity             -2496.     1831.    -1.36  1.74e-  1\n 4 wind_speed            -889.      308.    -2.89  4.26e-  3\n 5 vis                   -314.      373.    -0.843 4.00e-  1\n 6 dew_point_temp        8370.     5575.     1.50  1.35e-  1\n 7 solar_radiation       3879.      468.     8.28  7.45e- 15\n 8 rainfall             -2038.      345.    -5.90  1.16e-  8\n 9 snowfall              -312.      276.    -1.13  2.60e-  1\n10 seasons_Spring       -2337.      372.    -6.27  1.54e-  9\n11 seasons_Summer       -1409.      448.    -3.14  1.87e-  3\n12 seasons_Winter       -3865.      495.    -7.80  1.65e- 13\n13 holiday_No.Holiday     686.      262.     2.62  9.38e-  3\n14 day_type_Weekend      -936.      260.    -3.60  3.79e-  4\n\n\n\n\nLASSO model\n*Create a Model instance with tune()\n\nLASSO_spec &lt;- linear_reg(penalty = tune(), mixture = 1) |&gt;\n  set_engine(\"glmnet\")\n\n\ncreate a entire workflow\n\n\nLASSO_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_rec1) |&gt;\n  add_model(LASSO_spec)\n\nLASSO_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n*n Fit the model with tune_grid and grid_regular\n\nLASSO_grid &lt;- LASSO_wkf |&gt;\n  tune_grid(resamples = bike_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\nLASSO_grid\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\n\n\n\n\nLASSO_grid[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard       3431. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard       3431. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard       3431. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard       3431. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard       3431. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard       3431. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard       3431. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard       3431. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard       3431. Preprocessor1_Model009\n10 2.83e-10 rmse    standard       3431. Preprocessor1_Model010\n# ℹ 390 more rows\n\n\n\nLASSO_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\")\n\n# A tibble: 200 × 7\n    penalty .metric .estimator  mean     n std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   4171.    10    140. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard   4171.    10    140. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard   4171.    10    140. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard   4171.    10    140. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard   4171.    10    140. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard   4171.    10    140. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard   4171.    10    140. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard   4171.    10    140. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard   4171.    10    140. Preprocessor1_Model009\n10 2.83e-10 rmse    standard   4171.    10    140. Preprocessor1_Model010\n# ℹ 190 more rows\n\n\n\nPull out the best Model\n\n\nlowest_rmse &lt;- LASSO_grid |&gt;\n  select_best(metric = \"rmse\")\n\nlowest_rmse\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\n\n\nFit the best LASSO model on training set\n\n\nLASSO_final &lt;- LASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse) |&gt;\n  fit(bike_train)\ntidy(LASSO_final)\n\n# A tibble: 14 × 3\n   term               estimate      penalty\n   &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)          17670. 0.0000000001\n 2 temp                     0  0.0000000001\n 3 humidity             -1098. 0.0000000001\n 4 wind_speed            -889. 0.0000000001\n 5 vis                   -214. 0.0000000001\n 6 dew_point_temp        4083. 0.0000000001\n 7 solar_radiation       3849. 0.0000000001\n 8 rainfall             -2141. 0.0000000001\n 9 snowfall              -335. 0.0000000001\n10 seasons_Spring       -2290. 0.0000000001\n11 seasons_Summer       -1328. 0.0000000001\n12 seasons_Winter       -3809. 0.0000000001\n13 holiday_No.Holiday     686. 0.0000000001\n14 day_type_Weekend      -949. 0.0000000001\n\n\n\nCoefficient from LASSO model\n\n\n# LASSO_final |&gt;\n#   extract_fit_parsnip() |&gt;\n#   tidy()"
  },
  {
    "objectID": "HW09.html#regression-tree-model",
    "href": "HW09.html#regression-tree-model",
    "title": "HW09withjustin",
    "section": "Regression Tree Model",
    "text": "Regression Tree Model\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = tune(),\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n\nCreate a workflow\n\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_rec1) |&gt;\n  add_model(tree_mod)\n\n#tree_wkf\n\n\nTune regression tree\n\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(range = c(2,10)),\n                          min_n(range = c(5,20)),\n                          levels = 5)\n\n\nPerform cross-validation\n\n\ntree_tune &lt;- tree_wkf |&gt;\n  tune_grid(\n    resamples = bike_10_fold,\n    grid = tree_grid,\n    metrics = metric_set(rmse, mae)\n  )\n\n#tree_tune\n\n\n#prep(MLR_rec1) |&gt; bake(new_data = bike_train)\n\n\nSelect the best tree Model\n\n\nbest_tree &lt;- tree_tune |&gt; \n  select_best(metric = \"rmse\")\n#tree_best_params &lt;- select_best(tree_tune, metric = \"rmse\")\nbest_tree\n\n# A tibble: 1 × 4\n  cost_complexity tree_depth min_n .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 \n1    0.0000000001          6    20 Preprocessor1_Model111\n\n\n\nFit best model on Training set\n\n\nfinal_tree_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(best_tree)\n\n# Fit final mode on the training set\ntree_fit &lt;- final_tree_wkf|&gt;\n  fit(data = bike_train)\n\nEvaluate Model Performance on the Test Set\n\n# Predict on the test set\ntree_test_results &lt;- tree_fit %&gt;%\n  predict(new_data = bike_test) %&gt;%\n  bind_cols(bike_test) %&gt;%\n  metrics(truth = bike_count, estimate = .pred)\n\ntree_test_results\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard    3410.   \n2 rsq     standard       0.874\n3 mae     standard    2420.   \n\n\n\nPlot the tree\n\n\nlibrary(rpart.plot)\n\n# # Visualize the regression tree\n# tree_fit %&gt;%\n#   extract_fit_parsnip() %&gt;%\n#   rpart.plot::rpart.plot()"
  },
  {
    "objectID": "HW09.html#tuned-bagged-tree-model",
    "href": "HW09.html#tuned-bagged-tree-model",
    "title": "HW09withjustin",
    "section": "Tuned Bagged Tree Model",
    "text": "Tuned Bagged Tree Model\n\nbagged_tree &lt;- bag_tree(tree_depth = tune(),\n                        min_n = tune()) |&gt;\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"regression\")"
  },
  {
    "objectID": "HW09.html#random-forest",
    "href": "HW09.html#random-forest",
    "title": "HW09withjustin",
    "section": "Random Forest",
    "text": "Random Forest\n\nrf_spec &lt;- rand_forest(\n  mtry = tune(), \n  trees = 500, \n  min_n = tune()\n) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"regression\")\n\nWorkflow\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_rec1) |&gt;\n  add_model(rf_spec)\n\nHyperparameter Grid\n\n# Define the Grid for Tuning\nrf_grid &lt;- grid_regular(\n  mtry(range = c(1, ncol(bike_train) - 1)), \n  min_n(range = c(2, 10)),\n  levels = 5\n)\n\nCross-Validation\n\n# Tune the Random Forest Model\nrf_tune &lt;- rf_wkf |&gt;\n  tune_grid(\n    resamples = bike_10_fold,\n    grid = rf_grid,\n    metrics = metric_set(rmse, mae)  \n  )\n\nBest Hyperparameter\n\nbest_rf &lt;- rf_tune |&gt;\n  select_best(metric = \"rmse\")\n\n# View the Best Parameters\nprint(best_rf)\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     6     2 Preprocessor1_Model03\n\n\nworkflow and fit on Training data\n\n# Finalize Workflow with Best Parameters\nrf_fit &lt;- rf_wkf |&gt;\n  finalize_workflow(best_rf) |&gt;\n  fit(data = bike_train)\n\nModel on the Test Set\n\n# Make Predictions on Test Set\nrf_preds &lt;- predict(rf_fit, new_data = bike_test) |&gt;\n  bind_cols(bike_test)\n\n# Evaluate Model Performance\nrf_metrics &lt;- rf_preds |&gt;\n  metrics(truth = bike_count, estimate = .pred) # Replace 'Rental_Count' with your target variable\n\n# View the Metrics\nprint(rf_metrics)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard    2925.   \n2 rsq     standard       0.905\n3 mae     standard    2197.   \n\n\n##Model Comparisons on Test Set\n\n# LASSO model performance\nlasso_preds &lt;- predict(LASSO_final, new_data = bike_test) |&gt;\n  bind_cols(bike_test) |&gt;\n  metrics(truth = bike_count, estimate = .pred)\n\n\n# MLR model performance\n# Extract the workflow from the last_fit result\nfinal_fit_workflow &lt;- extract_workflow(final_fit)\n\n# Make predictions on the test set using the extracted workflow\nmlr_preds &lt;- predict(final_fit_workflow, new_data = bike_test) |&gt;\n  bind_cols(bike_test) |&gt;\n  metrics(truth = bike_count, estimate = .pred)\n\nmlr_preds\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard    3847.   \n2 rsq     standard       0.840\n3 mae     standard    2996.   \n\n\n\n# Regression Tree model performance\ntree_preds &lt;- predict(tree_fit, new_data = bike_test) |&gt;\n  bind_cols(bike_test) |&gt;\n  metrics(truth = bike_count, estimate = .pred)\n\n\n# Bagged Tree model performance\nbagged_tree_preds &lt;- predict(bagged_tree_fit, new_data = bike_test) |&gt;\n  bind_cols(bike_test) |&gt;\n  metrics(truth = bike_count, estimate = .pred)\n\n\n# Random Forest model performance\nrf_preds &lt;- predict(rf_fit, new_data = bike_test) |&gt;\n  bind_cols(bike_test) |&gt;\n  metrics(truth = bike_count, estimate = .pred)\n\n\n# Combine all metrics\nmodel_comparison &lt;- bind_rows(\n  lasso_preds |&gt; mutate(Model = \"LASSO\"),\n  mlr_preds |&gt; mutate(Model = \"MLR\"),\n  tree_preds |&gt; mutate(Model = \"Regression Tree\"),\n  bagged_tree_preds |&gt; mutate(Model = \"Bagged Tree\"),\n  rf_preds |&gt; mutate(Model = \"Random Forest\")\n)\nmodel_comparison\n\n# A tibble: 15 × 4\n   .metric .estimator .estimate Model          \n   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n 1 rmse    standard    3863.    LASSO          \n 2 rsq     standard       0.838 LASSO          \n 3 mae     standard    3008.    LASSO          \n 4 rmse    standard    3847.    MLR            \n 5 rsq     standard       0.840 MLR            \n 6 mae     standard    2996.    MLR            \n 7 rmse    standard    3410.    Regression Tree\n 8 rsq     standard       0.874 Regression Tree\n 9 mae     standard    2420.    Regression Tree\n10 rmse    standard    3049.    Bagged Tree    \n11 rsq     standard       0.897 Bagged Tree    \n12 mae     standard    2194.    Bagged Tree    \n13 rmse    standard    2925.    Random Forest  \n14 rsq     standard       0.905 Random Forest  \n15 mae     standard    2197.    Random Forest  \n\n\n\nmodel_comparison |&gt; \n  filter(.metric == \"rmse\") |&gt; \n  select(Model, .estimate) |&gt; \n  arrange(.estimate)\n\n# A tibble: 5 × 2\n  Model           .estimate\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Random Forest       2925.\n2 Bagged Tree         3049.\n3 Regression Tree     3410.\n4 MLR                 3847.\n5 LASSO               3863.\n\n\nMLR and LASSO model for final coefficient\n\n# MLR model final coefficients\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 5\n   term               estimate std.error statistic   p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          17670.      256.    69.1   1.60e-164\n 2 temp                 -3580.     4750.    -0.754 4.52e-  1\n 3 humidity             -2496.     1831.    -1.36  1.74e-  1\n 4 wind_speed            -889.      308.    -2.89  4.26e-  3\n 5 vis                   -314.      373.    -0.843 4.00e-  1\n 6 dew_point_temp        8370.     5575.     1.50  1.35e-  1\n 7 solar_radiation       3879.      468.     8.28  7.45e- 15\n 8 rainfall             -2038.      345.    -5.90  1.16e-  8\n 9 snowfall              -312.      276.    -1.13  2.60e-  1\n10 seasons_Spring       -2337.      372.    -6.27  1.54e-  9\n11 seasons_Summer       -1409.      448.    -3.14  1.87e-  3\n12 seasons_Winter       -3865.      495.    -7.80  1.65e- 13\n13 holiday_No.Holiday     686.      262.     2.62  9.38e-  3\n14 day_type_Weekend      -936.      260.    -3.60  3.79e-  4\n\n# LASSO model final coefficients\nLASSO_final |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 3\n   term               estimate      penalty\n   &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)          17670. 0.0000000001\n 2 temp                     0  0.0000000001\n 3 humidity             -1098. 0.0000000001\n 4 wind_speed            -889. 0.0000000001\n 5 vis                   -214. 0.0000000001\n 6 dew_point_temp        4083. 0.0000000001\n 7 solar_radiation       3849. 0.0000000001\n 8 rainfall             -2141. 0.0000000001\n 9 snowfall              -335. 0.0000000001\n10 seasons_Spring       -2290. 0.0000000001\n11 seasons_Summer       -1328. 0.0000000001\n12 seasons_Winter       -3809. 0.0000000001\n13 holiday_No.Holiday     686. 0.0000000001\n14 day_type_Weekend      -949. 0.0000000001\n\n\nRegression Tree Model: Plot the final fit\n\n# Plot the final regression tree\n# Extract the fitted model from the parsnip workflow\nrpart_model &lt;- tree_fit |&gt;\n  extract_fit_parsnip()\n\n# Plot the regression tree\n\npar(mar = c(5, 4, 4, 2))  \nrpart.plot::rpart.plot(rpart_model$fit, roundint = FALSE)\n\n\n\n\n\n\n\n\nBagged Tree and Random Forest Models: Produce variable importance plots\n\n# Bagged Tree variable importance plot\nrpart_model &lt;- bagged_tree_fit$fit\nrpart_model$variable.importance  # Variable importance for rpart-based models\n\nNULL\n\n\n\n# Random Forest variable importance plot\n#install.packages(\"workflows\")\n# rf_fit %&gt;%\n#   extract_fit_parsnip() %&gt;%\n#   vip::vip()\n\nBest Model, Fit it to the Entire Dataset\n\n# Example: Refit the Random Forest (assuming it was the best based on the test set performance)\n# final_rf_fit &lt;- rf_wkf %&gt;%\n#   finalize_workflow(best_rf) %&gt;%\n#   fit(data = bike_data)\n# \n# # Check the final model performance on the full dataset\n# final_rf_fit"
  }
]